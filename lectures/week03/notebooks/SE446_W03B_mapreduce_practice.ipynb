{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4245228",
   "metadata": {},
   "source": [
    "# SE446 - Week 3B: MapReduce Practice with Crime Data\n",
    "\n",
    "## \ud83d\udcda Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Apply MapReduce to analyze real-world crime data\n",
    "2. Implement various aggregation patterns (count, sum, average)\n",
    "3. Chain multiple MapReduce jobs for complex analysis\n",
    "4. Debug and optimize MapReduce code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ed0d9",
   "metadata": {},
   "source": [
    "## 1. Setup: Load the MapReduce Framework (Emulator)\n",
    "\n",
    "### \u26a0\ufe0f Reminder: Local Emulation\n",
    "The code below defines a **local Python emulator** for MapReduce. \n",
    "\n",
    "**Purpose:**\n",
    "- It allows us to run MapReduce logic on small datasets directly in this notebook.\n",
    "- It mimics the core behavior of a distributed system (Map \u2192 Shuffle \u2192 Reduce) using standard Python loops and dictionaries.\n",
    "- In a real project, this same logic would run on a Hadoop cluster where the \"loops\" are replaced by parallel processing on many machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def map_reduce(data, mapper, reducer):\n",
    "    \"\"\"\n",
    "    Simple MapReduce implementation.\n",
    "    \"\"\"\n",
    "    # MAP PHASE\n",
    "    mapped = []\n",
    "    for record in data:\n",
    "        result = mapper(record)\n",
    "        if result is not None:\n",
    "            if isinstance(result, list):\n",
    "                mapped.extend(result)\n",
    "            else:\n",
    "                mapped.append(result)\n",
    "    \n",
    "    # SHUFFLE PHASE\n",
    "    shuffled = defaultdict(list)\n",
    "    for key, value in mapped:\n",
    "        shuffled[key].append(value)\n",
    "    \n",
    "    # REDUCE PHASE\n",
    "    results = []\n",
    "    for key, values in shuffled.items():\n",
    "        result = reducer(key, values)\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"\u2705 MapReduce framework loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af200f70",
   "metadata": {},
   "source": [
    "## 2. Load Chicago Crime Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58028679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Synthetic Crime Data \ud83c\udfb2\n",
    "# ------------------------------------------------------------------\n",
    "# Instead of downloading a potentially small or missing external file,\n",
    "# we generate a robust dataset of 1,000 records right here.\n",
    "# This ensures everyone has the exact same data for practice.\n",
    "\n",
    "print(\"\u26a0\ufe0f Generating 1,000 entries of synthetic crime data...\")\n",
    "\n",
    "crimes_df = pd.DataFrame({\n",
    "    'ID': range(1, 1001),\n",
    "    'Primary Type': ['THEFT']*300 + ['BATTERY']*250 + ['ASSAULT']*150 + \n",
    "                   ['CRIMINAL DAMAGE']*100 + ['BURGLARY']*100 + ['OTHER']*100,\n",
    "    'District': [1]*100 + [2]*150 + [3]*200 + [4]*150 + [5]*100 + \n",
    "               [6]*100 + [7]*100 + [8]*100,\n",
    "    'Arrest': [True]*350 + [False]*650,\n",
    "    'Location Description': ['STREET']*400 + ['RESIDENCE']*300 + \n",
    "                           ['APARTMENT']*150 + ['STORE']*150\n",
    "})\n",
    "\n",
    "# Shuffle the dataset so patterns aren't just sequential\n",
    "crimes_df = crimes_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\u2705 Created {len(crimes_df):,} sample records\")\n",
    "\n",
    "# Convert to list of dictionaries for MapReduce\n",
    "crime_records = crimes_df.to_dict('records')\n",
    "\n",
    "# Preview columns\n",
    "print(f\"\\n\ud83d\udccb Columns: {list(crimes_df.columns)}\")\n",
    "crimes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7246856",
   "metadata": {},
   "source": [
    "## 3. Exercise 1: Count Crimes by Type \ud83d\udcca\n",
    "\n",
    "**Goal**: Count how many crimes of each type occurred.\n",
    "\n",
    "**Key**: Crime type (e.g., \"THEFT\", \"ASSAULT\")  \n",
    "**Value**: 1 (for counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper: emit (crime_type, 1) for each crime record\n",
    "def crime_type_mapper(record):\n",
    "    \"\"\"\n",
    "    Input: Crime record (dict)\n",
    "    Output: (crime_type, 1)\n",
    "    \"\"\"\n",
    "    crime_type = record['Primary Type']\n",
    "    return (crime_type, 1)\n",
    "\n",
    "# Reducer: sum all counts for each crime type\n",
    "def count_reducer(key, values):\n",
    "    \"\"\"\n",
    "    Input: crime_type, list of 1s\n",
    "    Output: (crime_type, total_count)\n",
    "    \"\"\"\n",
    "    return (key, sum(values))\n",
    "\n",
    "# Run MapReduce\n",
    "crime_counts = map_reduce(crime_records, crime_type_mapper, count_reducer)\n",
    "\n",
    "# Display results (sorted by count)\n",
    "print(\"\\n\ud83d\udcca Crime Counts by Type:\")\n",
    "print(\"-\" * 40)\n",
    "for crime_type, count in sorted(crime_counts, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{crime_type:25} {count:>6,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a712b9f",
   "metadata": {},
   "source": [
    "## 4. Exercise 2: Crimes per District \ud83c\udfe2\n",
    "\n",
    "**Goal**: Count crimes in each police district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5470fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the mapper\n",
    "def district_mapper(record):\n",
    "    \"\"\"\n",
    "    Input: Crime record (dict)\n",
    "    Output: (district, 1)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    district = record['District']\n",
    "    return (district, 1)\n",
    "\n",
    "# Run MapReduce (reuse count_reducer)\n",
    "district_counts = map_reduce(crime_records, district_mapper, count_reducer)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\ud83c\udfe2 Crimes by District:\")\n",
    "print(\"-\" * 30)\n",
    "for district, count in sorted(district_counts, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"District {district:>3}: {count:>6,} crimes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc696e3",
   "metadata": {},
   "source": [
    "## 5. Exercise 3: Filter - Only Crimes with Arrests \ud83d\ude94\n",
    "\n",
    "**Goal**: Count only crimes where an arrest was made.\n",
    "\n",
    "**Pattern**: Return `None` from mapper to filter records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82fec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrest_filter_mapper(record):\n",
    "    \"\"\"\n",
    "    Only emit crimes where Arrest == True\n",
    "    \"\"\"\n",
    "    # Filter: only process if arrest was made\n",
    "    if record.get('Arrest') == True:\n",
    "        return (record['Primary Type'], 1)\n",
    "    else:\n",
    "        return None  # Filter out - skip this record\n",
    "\n",
    "# Run MapReduce\n",
    "arrest_counts = map_reduce(crime_records, arrest_filter_mapper, count_reducer)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\ud83d\ude94 Crimes with Arrests:\")\n",
    "print(\"-\" * 40)\n",
    "for crime_type, count in sorted(arrest_counts, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{crime_type:25} {count:>6,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353abafa",
   "metadata": {},
   "source": [
    "## 6. Exercise 4: Calculate Arrest Rate \ud83d\udcc8\n",
    "\n",
    "**Goal**: Calculate arrest rate (%) for each crime type.\n",
    "\n",
    "**Key**: Crime type  \n",
    "**Value**: (arrested, total) - tuple for computing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrest_rate_mapper(record):\n",
    "    \"\"\"\n",
    "    Emit (crime_type, (arrested, total))\n",
    "    - arrested: 1 if arrest made, 0 otherwise\n",
    "    - total: always 1 (for counting)\n",
    "    \"\"\"\n",
    "    crime_type = record['Primary Type']\n",
    "    arrested = 1 if record.get('Arrest') == True else 0\n",
    "    return (crime_type, (arrested, 1))\n",
    "\n",
    "def arrest_rate_reducer(crime_type, values):\n",
    "    \"\"\"\n",
    "    Calculate arrest rate from list of (arrested, total) tuples\n",
    "    \"\"\"\n",
    "    total_arrests = sum(v[0] for v in values)\n",
    "    total_crimes = sum(v[1] for v in values)\n",
    "    \n",
    "    if total_crimes > 0:\n",
    "        rate = (total_arrests / total_crimes) * 100\n",
    "    else:\n",
    "        rate = 0\n",
    "    \n",
    "    return (crime_type, {\n",
    "        'arrests': total_arrests,\n",
    "        'total': total_crimes,\n",
    "        'rate': round(rate, 1)\n",
    "    })\n",
    "\n",
    "# Run MapReduce\n",
    "arrest_rates = map_reduce(crime_records, arrest_rate_mapper, arrest_rate_reducer)\n",
    "\n",
    "# Display results (sorted by rate)\n",
    "print(\"\\n\ud83d\udcc8 Arrest Rates by Crime Type:\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Crime Type':25} {'Arrests':>8} {'Total':>8} {'Rate':>8}\")\n",
    "print(\"-\" * 55)\n",
    "for crime_type, stats in sorted(arrest_rates, key=lambda x: x[1]['rate'], reverse=True)[:10]:\n",
    "    print(f\"{crime_type:25} {stats['arrests']:>8,} {stats['total']:>8,} {stats['rate']:>7.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f4089",
   "metadata": {},
   "source": [
    "## 7. Exercise 5: Multi-Stage - Top 5 Crime Types \ud83c\udfc6\n",
    "\n",
    "**Goal**: Find the 5 most common crime types.\n",
    "\n",
    "**Approach**: Two-stage MapReduce\n",
    "1. **Stage 1**: Count crimes by type\n",
    "2. **Stage 2**: Find top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b09ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Count by type (already done above)\n",
    "crime_counts = map_reduce(crime_records, crime_type_mapper, count_reducer)\n",
    "print(f\"Stage 1: Got {len(crime_counts)} crime types\")\n",
    "\n",
    "# Stage 2: Find top 5\n",
    "def top_n_mapper(item):\n",
    "    \"\"\"\n",
    "    Send all items to same reducer using dummy key\n",
    "    \"\"\"\n",
    "    crime_type, count = item\n",
    "    return (\"all\", (crime_type, count))  # Key=\"all\" sends everything to one reducer\n",
    "\n",
    "def top_5_reducer(key, values):\n",
    "    \"\"\"\n",
    "    Sort and return top 5\n",
    "    \"\"\"\n",
    "    sorted_values = sorted(values, key=lambda x: x[1], reverse=True)\n",
    "    return (key, sorted_values[:5])\n",
    "\n",
    "# Run Stage 2\n",
    "top_5_result = map_reduce(crime_counts, top_n_mapper, top_5_reducer)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\ud83c\udfc6 Top 5 Crime Types:\")\n",
    "print(\"-\" * 40)\n",
    "for rank, (crime_type, count) in enumerate(top_5_result[0][1], 1):\n",
    "    print(f\"#{rank}: {crime_type:25} {count:>6,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79ad76",
   "metadata": {},
   "source": [
    "## 8. \ud83c\udfaf Challenge Exercise: Crime Hot Spots\n",
    "\n",
    "**Goal**: Find the top 3 crime locations for each crime type.\n",
    "\n",
    "This requires thinking carefully about keys and multi-stage processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your solution\n",
    "\n",
    "# Stage 1: Count (crime_type, location) combinations\n",
    "def type_location_mapper(record):\n",
    "    crime_type = record['Primary Type']\n",
    "    location = record.get('Location Description', 'UNKNOWN')\n",
    "    # Composite key: (crime_type, location)\n",
    "    return ((crime_type, location), 1)\n",
    "\n",
    "# Run Stage 1\n",
    "type_location_counts = map_reduce(crime_records, type_location_mapper, count_reducer)\n",
    "\n",
    "# Stage 2: Group by crime type and find top 3 locations\n",
    "def group_by_type_mapper(item):\n",
    "    (crime_type, location), count = item\n",
    "    return (crime_type, (location, count))\n",
    "\n",
    "def top_3_locations_reducer(crime_type, values):\n",
    "    sorted_locations = sorted(values, key=lambda x: x[1], reverse=True)[:3]\n",
    "    return (crime_type, sorted_locations)\n",
    "\n",
    "# Run Stage 2\n",
    "crime_hotspots = map_reduce(type_location_counts, group_by_type_mapper, top_3_locations_reducer)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\ud83d\udd25 Crime Hot Spots (Top 3 Locations per Type):\")\n",
    "print(\"=\" * 60)\n",
    "for crime_type, locations in sorted(crime_hotspots, key=lambda x: x[0])[:5]:  # Show first 5 types\n",
    "    print(f\"\\n{crime_type}:\")\n",
    "    for location, count in locations:\n",
    "        print(f\"  \u2022 {location}: {count:,} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e4163",
   "metadata": {},
   "source": [
    "## 9. Summary: MapReduce Patterns\n",
    "\n",
    "| Pattern | Mapper Output | Reducer Operation |\n",
    "|---------|---------------|------------------|\n",
    "| **Count** | `(key, 1)` | `sum(values)` |\n",
    "| **Sum** | `(key, value)` | `sum(values)` |\n",
    "| **Average** | `(key, (value, 1))` | `sum(v)/sum(c)` |\n",
    "| **Filter** | `(key, value)` or `None` | pass through |\n",
    "| **Top N** | `(\"all\", (key, value))` | sort and slice |\n",
    "\n",
    "### Key Design Questions\n",
    "\n",
    "1. **What is my key?** \u2192 What do I want to group by?\n",
    "2. **What is my value?** \u2192 What do I want to aggregate?\n",
    "3. **Do I need multiple stages?** \u2192 Complex aggregations often do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182c7fb",
   "metadata": {},
   "source": [
    "## 10. \ud83d\udcdd Homework: Milestone 2 Preparation\n",
    "\n",
    "For Milestone 2, you'll implement MapReduce analysis on the crime dataset.\n",
    "\n",
    "**Tasks to prepare:**\n",
    "1. Review all patterns from this notebook\n",
    "2. Clone your team's GitHub repo\n",
    "3. Copy the starter notebook to your folder\n",
    "4. Begin implementing the required analyses\n",
    "\n",
    "**Remember:** Commit frequently with meaningful messages!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}