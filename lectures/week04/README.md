# Week 4: Apache Hive

## Overview

This week introduces Apache Hive â€” the SQL-on-Hadoop system that allows data analysts and engineers to query massive datasets stored in HDFS using a familiar SQL-like language (HiveQL). Students will learn Hive architecture, data model, and how to write analytical queries without writing low-level MapReduce code.

---

## Session 4A: Introduction to Apache Hive

### Learning Objectives
1. Explain how Hive provides a SQL interface to HDFS
2. Understand schema-on-read vs. schema-on-write
3. Describe Hive architecture (Driver, Metastore, Execution Engine)
4. Distinguish managed vs. external tables
5. Explain partitioning and bucketing strategies
6. Compare file formats: TextFile, ORC, Parquet

### Pre-Class Video
**"Apache Hive Tutorial"** - Simplilearn (~25 min)  
ğŸ”— https://www.youtube.com/watch?v=tKNGB5IZPFE

**Alternative**: "Hive Explained in 10 Minutes" - ByteByteGo  
ğŸ”— https://www.youtube.com/watch?v=Hs1S1JhS7lY

### Materials
- ğŸ“Š Slides: `slides/SE446_W04A_hive_fundamentals.pdf`

---

## Session 4B: HiveQL Queries in Practice

### Learning Objectives
1. Create databases and tables in Hive (DDL)
2. Load data from local filesystem and HDFS into Hive tables
3. Write analytical queries using SELECT, GROUP BY, HAVING, ORDER BY
4. Perform JOINs across tables
5. Use built-in string, date, numeric, and window functions
6. Optimize queries using partitioning, ORC format, and EXPLAIN

### Pre-Class Video
**"HiveQL Tutorial for Beginners"** - Edureka (~30 min)  
ğŸ”— https://www.youtube.com/watch?v=2H_yVFGEp3A

### Materials
- ğŸ“Š Slides: `slides/SE446_W04B_hiveql_queries.pdf`

---

## Key Concepts

### Hive in the Hadoop Ecosystem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HIVE ARCHITECTURE                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  USER (SQL)                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚  SELECT primary_type, COUNT(*) FROM crimes GROUP BY primary_type;           â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  HiveServer2 (Thrift Server)                                     â”‚      â”‚
â”‚  â”‚  Accepts Beeline, JDBC, ODBC connections                         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  DRIVER                                                          â”‚      â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚      â”‚
â”‚  â”‚  1. Parser:    SQL â†’ Abstract Syntax Tree (AST)                 â”‚      â”‚
â”‚  â”‚  2. Compiler:  AST â†’ Logical Plan                                â”‚      â”‚
â”‚  â”‚  3. Optimizer: Predicate pushdown, partition pruning             â”‚      â”‚
â”‚  â”‚  4. Executor:  Physical plan â†’ MapReduce / Tez / Spark jobs     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                     â”‚                     â”‚                                  â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚           â”‚     METASTORE     â”‚ â”‚  EXECUTION ENGINE  â”‚                      â”‚
â”‚           â”‚  (MySQL/Derby)    â”‚ â”‚  (Tez/MR/Spark)    â”‚                      â”‚
â”‚           â”‚  - Table schemas  â”‚ â”‚  - Runs on YARN    â”‚                      â”‚
â”‚           â”‚  - Partition info â”‚ â”‚  - Reads from HDFS â”‚                      â”‚
â”‚           â”‚  - File locations â”‚ â”‚                    â”‚                      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                     â”‚                     â”‚                                  â”‚
â”‚                     â–¼                     â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                            HDFS                                  â”‚      â”‚
â”‚  â”‚  /warehouse/crimes/year=2023/part-00000.orc                      â”‚      â”‚
â”‚  â”‚  /warehouse/crimes/year=2024/part-00000.orc                      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Managed vs. External Tables

| Feature | Managed Table | External Table |
|---------|--------------|----------------|
| Data ownership | Hive owns data | Hive only owns metadata |
| DROP TABLE | Deletes data + metadata | Deletes metadata only |
| Data location | Hive warehouse dir | Custom HDFS location |
| Best for | Intermediate/derived data | Raw/shared data |

### Partitioning vs. Bucketing

| Feature | Partitioning | Bucketing |
|---------|-------------|-----------|
| Physical layout | Subdirectories | Files within directory |
| Based on | Column value | Hash of column |
| Cardinality | Low (year, country) | High (user_id) |
| Benefit | Partition pruning | Efficient joins & sampling |

### File Format Comparison

| Format | Type | Compressed | Best For |
|--------|------|-----------|----------|
| TextFile | Row | No | Simple CSV input |
| ORC | Columnar | Yes | Hive-optimized analytics |
| Parquet | Columnar | Yes | Cross-platform (Spark) |
| Avro | Row | Yes | Schema evolution |

---

## HiveQL Quick Reference

### DDL Commands
```sql
-- Create database
CREATE DATABASE IF NOT EXISTS my_db;
USE my_db;

-- Create external table from CSV
CREATE EXTERNAL TABLE crimes (
    case_number STRING, primary_type STRING, arrest BOOLEAN, district INT
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/data/crimes/'
TBLPROPERTIES ("skip.header.line.count"="1");

-- Create partitioned ORC table
CREATE TABLE crimes_orc (...)
PARTITIONED BY (year INT)
STORED AS ORC;

-- Inspect table
DESCRIBE FORMATTED crimes;
SHOW PARTITIONS crimes_orc;
```

### Loading Data
```sql
-- From local filesystem
LOAD DATA LOCAL INPATH '/path/to/file.csv' INTO TABLE crimes;

-- From HDFS (moves the file!)
LOAD DATA INPATH '/staging/file.csv' INTO TABLE crimes;

-- Insert from another table (ETL)
INSERT OVERWRITE TABLE crimes_orc PARTITION (year)
SELECT *, YEAR(date_str) AS year FROM crimes;

-- CTAS: Create + populate in one step
CREATE TABLE theft_crimes STORED AS ORC AS
SELECT * FROM crimes WHERE primary_type = 'THEFT';
```

### Analytical Queries
```sql
-- Top crime types
SELECT primary_type, COUNT(*) AS cnt
FROM crimes GROUP BY primary_type
ORDER BY cnt DESC LIMIT 10;

-- Arrest rate by district
SELECT district, COUNT(*) AS total,
       ROUND(SUM(CASE WHEN arrest THEN 1 ELSE 0 END)*100.0/COUNT(*),2) AS pct
FROM crimes GROUP BY district;

-- Window function: rank within district
SELECT district, primary_type, crime_count,
       RANK() OVER (PARTITION BY district ORDER BY crime_count DESC) AS rnk
FROM crime_summary;
```

---

## Datasets Used This Week

| Dataset | Source | Description |
|---------|--------|-------------|
| `chicago_crimes_sample.csv` | `data/` folder | 30 crime incidents |
| `nyc_taxi_sample.csv` | `data/` folder | 50 taxi trips |
| `nyc_weather_sample.csv` | `data/` folder | 40 daily weather records |

---

## Lab Deliverables

1. **Database setup**: Create team database on the Hive cluster
2. **Table creation**: Load Chicago crimes into both TextFile and ORC tables
3. **Analytical queries**: Write 5+ HiveQL queries with GROUP BY, JOINs, and window functions
4. **Performance comparison**: Compare query times between TextFile and ORC
5. **Export results**: Save top-10 crime types to HDFS as CSV
6. **Commit**: Push all `.hql` scripts to your team GitHub repo

---

## Additional Resources

- ğŸ“– [Apache Hive Documentation](https://hive.apache.org/)
- ğŸ“– [HiveQL Language Manual](https://cwiki.apache.org/confluence/display/Hive/LanguageManual)
- ğŸ¥ [Hive Architecture Deep Dive - Cloudera](https://www.youtube.com/watch?v=8jMV9F0xUKk)
- ğŸ“– [ORC File Format Specification](https://orc.apache.org/specification/)
