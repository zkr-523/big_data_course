{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# SE446 - Week 4A: HiveQL Practice with Emulator\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Write DDL statements (CREATE TABLE, DROP TABLE, DESCRIBE)\n",
    "2. Query data using SELECT, WHERE, GROUP BY, ORDER BY, LIMIT\n",
    "3. Use aggregation functions and HAVING clauses\n",
    "4. Perform JOINs across multiple tables\n",
    "5. Apply window functions (RANK, ROW_NUMBER, running totals)\n",
    "6. Read EXPLAIN output to understand query execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Setup: The HiveQL Emulator\n",
    "\n",
    "### ‚ö†Ô∏è Important Context: Emulation vs. Real Cluster\n",
    "\n",
    "**Note:** Just like we used a Python emulator for MapReduce in Week 3, this notebook uses a **local SQLite-based emulator** to practice HiveQL.\n",
    "\n",
    "**Why use an emulator?**\n",
    "- Practice SQL/HiveQL syntax without needing cluster access\n",
    "- Instant feedback ‚Äî no waiting for YARN to schedule jobs\n",
    "- Focus on **query logic**, not infrastructure\n",
    "\n",
    "**What's the same?** The SQL syntax you learn here is nearly identical to what you'll run on the real Hive cluster in Notebook 4B.\n",
    "\n",
    "**What's different?** Real Hive translates your SQL into MapReduce/Tez jobs that run across the cluster. Here, SQLite processes everything locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Create in-memory database (like Hive's Metastore + HDFS combined)\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "def hive_query(sql, show=True):\n",
    "    \"\"\"\n",
    "    Execute a HiveQL-compatible query and display results.\n",
    "    \n",
    "    Parameters:\n",
    "    - sql: SQL query string\n",
    "    - show: if True, display results as DataFrame\n",
    "    \n",
    "    Returns: pandas DataFrame of results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = conn.execute(sql)\n",
    "        if cursor.description:  # SELECT queries return data\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            rows = cursor.fetchall()\n",
    "            df = pd.DataFrame(rows, columns=columns)\n",
    "            if show:\n",
    "                display(df)\n",
    "            return df\n",
    "        else:  # DDL/DML queries (CREATE, INSERT, etc.)\n",
    "            conn.commit()\n",
    "            print(f\"‚úÖ Query executed successfully.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ HiveQL Emulator ready!\")\n",
    "print(\"   Use hive_query('YOUR SQL HERE') to run queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## 2. Generate Datasets\n",
    "\n",
    "We'll create three datasets to practice with:\n",
    "\n",
    "| Dataset | Rows | Purpose |\n",
    "|---------|------|---------|\n",
    "| `chicago_crimes` | 1,000 | Crime analysis (DDL, aggregations) |\n",
    "| `nyc_taxi` | 500 | Trip data (JOINs with weather) |\n",
    "| `nyc_weather` | 365 | Weather conditions (JOIN target) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Dataset 1: Chicago Crimes (1,000 records)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "crime_types = ['THEFT', 'BATTERY', 'ASSAULT', 'CRIMINAL DAMAGE', 'BURGLARY', 'NARCOTICS']\n",
    "crime_weights = [300, 250, 150, 120, 100, 80]\n",
    "locations = ['STREET', 'RESIDENCE', 'APARTMENT', 'SIDEWALK', 'STORE', 'PARKING LOT']\n",
    "districts = list(range(1, 9))\n",
    "\n",
    "crimes_data = []\n",
    "for i in range(1, 1001):\n",
    "    ct = random.choices(crime_types, weights=crime_weights, k=1)[0]\n",
    "    year = random.choice([2019, 2020, 2021, 2022, 2023, 2024])\n",
    "    month = random.randint(1, 12)\n",
    "    day = random.randint(1, 28)\n",
    "    crimes_data.append((\n",
    "        i,\n",
    "        f'HX{random.randint(100000,999999)}',\n",
    "        f'{month:02d}/{day:02d}/{year}',\n",
    "        ct,\n",
    "        random.choice(locations),\n",
    "        random.choice(districts),\n",
    "        random.choice([True, False]),\n",
    "    ))\n",
    "\n",
    "conn.execute('''CREATE TABLE chicago_crimes (\n",
    "    id INTEGER, case_number TEXT, date TEXT,\n",
    "    primary_type TEXT, location_desc TEXT,\n",
    "    district INTEGER, arrest BOOLEAN\n",
    ")''')\n",
    "conn.executemany('INSERT INTO chicago_crimes VALUES (?,?,?,?,?,?,?)', crimes_data)\n",
    "conn.commit()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Dataset 2: NYC Taxi Trips (500 records)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "payment_types = ['Credit Card', 'Cash', 'No Charge', 'Dispute']\n",
    "taxi_data = []\n",
    "for i in range(1, 501):\n",
    "    day_offset = random.randint(0, 364)\n",
    "    month = (day_offset // 30) + 1\n",
    "    if month > 12: month = 12\n",
    "    day = (day_offset % 28) + 1\n",
    "    pickup_date = f'2024-{month:02d}-{day:02d}'\n",
    "    distance = round(random.uniform(0.5, 25.0), 1)\n",
    "    fare = round(distance * 2.5 + random.uniform(2, 8), 2)\n",
    "    tip = round(fare * random.uniform(0, 0.3), 2)\n",
    "    taxi_data.append((\n",
    "        i, pickup_date, distance, fare, tip,\n",
    "        round(fare + tip, 2),\n",
    "        random.choice(payment_types)\n",
    "    ))\n",
    "\n",
    "conn.execute('''CREATE TABLE nyc_taxi (\n",
    "    trip_id INTEGER, pickup_date TEXT, distance REAL,\n",
    "    fare REAL, tip REAL, total REAL, payment_type TEXT\n",
    ")''')\n",
    "conn.executemany('INSERT INTO nyc_taxi VALUES (?,?,?,?,?,?,?)', taxi_data)\n",
    "conn.commit()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Dataset 3: NYC Weather (365 records)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "conditions = ['Clear', 'Cloudy', 'Rain', 'Snow', 'Fog']\n",
    "weather_data = []\n",
    "for day_offset in range(365):\n",
    "    month = (day_offset // 30) + 1\n",
    "    if month > 12: month = 12\n",
    "    day = (day_offset % 28) + 1\n",
    "    date = f'2024-{month:02d}-{day:02d}'\n",
    "    # Seasonal temperature variation\n",
    "    base_temp = 50 + 25 * (1 - abs(month - 7) / 6)\n",
    "    temp_high = round(base_temp + random.uniform(-5, 5), 1)\n",
    "    temp_low = round(temp_high - random.uniform(8, 18), 1)\n",
    "    precip = round(random.uniform(0, 1.5), 2) if random.random() < 0.3 else 0.0\n",
    "    cond = 'Rain' if precip > 0.5 else ('Snow' if precip > 0 and temp_high < 35 else random.choice(['Clear', 'Cloudy', 'Fog']))\n",
    "    weather_data.append((date, temp_high, temp_low, precip, cond))\n",
    "\n",
    "conn.execute('''CREATE TABLE nyc_weather (\n",
    "    date TEXT, temp_high REAL, temp_low REAL,\n",
    "    precipitation REAL, condition TEXT\n",
    ")''')\n",
    "conn.executemany('INSERT INTO nyc_weather VALUES (?,?,?,?,?)', weather_data)\n",
    "conn.commit()\n",
    "\n",
    "print(\"‚úÖ All datasets loaded!\")\n",
    "print(f\"   üìä chicago_crimes: {len(crimes_data):,} rows\")\n",
    "print(f\"   üìä nyc_taxi:       {len(taxi_data):,} rows\")\n",
    "print(f\"   üìä nyc_weather:    {len(weather_data):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview of each table\n",
    "print(\"‚îÄ‚îÄ Chicago Crimes (first 5 rows) ‚îÄ‚îÄ\")\n",
    "hive_query('SELECT * FROM chicago_crimes LIMIT 5')\n",
    "\n",
    "print(\"\\n‚îÄ‚îÄ NYC Taxi (first 5 rows) ‚îÄ‚îÄ\")\n",
    "hive_query('SELECT * FROM nyc_taxi LIMIT 5')\n",
    "\n",
    "print(\"\\n‚îÄ‚îÄ NYC Weather (first 5 rows) ‚îÄ‚îÄ\")\n",
    "hive_query('SELECT * FROM nyc_weather LIMIT 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Exercise 1: DDL ‚Äî Creating and Inspecting Tables üèóÔ∏è\n",
    "\n",
    "In Hive, you define tables using **DDL** (Data Definition Language) statements.\n",
    "\n",
    "### Key HiveQL DDL Commands\n",
    "\n",
    "| Command | Purpose |\n",
    "|---------|--------|\n",
    "| `CREATE TABLE` | Define a new table |\n",
    "| `CREATE EXTERNAL TABLE` | Define table over existing HDFS data |\n",
    "| `DROP TABLE` | Remove a table |\n",
    "| `DESCRIBE table_name` | Show column names and types |\n",
    "| `SHOW TABLES` | List all tables in current database |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW TABLES ‚Äî List all tables\n",
    "# In Hive: SHOW TABLES;\n",
    "# In our emulator (SQLite):\n",
    "hive_query(\"SELECT name FROM sqlite_master WHERE type='table'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIBE ‚Äî Inspect table structure\n",
    "# In Hive: DESCRIBE chicago_crimes;\n",
    "# In our emulator (SQLite):\n",
    "hive_query(\"PRAGMA table_info(chicago_crimes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE ‚Äî Let's create a new summary table\n",
    "# In Hive this would be: CREATE TABLE crime_summary AS SELECT ...\n",
    "# This is called CTAS (Create Table As Select)\n",
    "\n",
    "hive_query('''\n",
    "    CREATE TABLE crime_summary AS\n",
    "    SELECT primary_type, COUNT(*) as total_crimes\n",
    "    FROM chicago_crimes\n",
    "    GROUP BY primary_type\n",
    "''')\n",
    "\n",
    "# Verify it was created\n",
    "hive_query('SELECT * FROM crime_summary ORDER BY total_crimes DESC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP TABLE ‚Äî Remove a table\n",
    "hive_query('DROP TABLE crime_summary')\n",
    "\n",
    "# Verify it's gone\n",
    "hive_query(\"SELECT name FROM sqlite_master WHERE type='table'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "### üéØ Your Turn: DDL Practice\n",
    "\n",
    "**Task**: Create a table called `theft_crimes` containing only THEFT records from `chicago_crimes`, then inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create table theft_crimes using CTAS\n",
    "# Hint: CREATE TABLE theft_crimes AS SELECT ... WHERE primary_type = 'THEFT'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# TODO: Count how many rows are in theft_crimes\n",
    "# Hint: SELECT COUNT(*) ...\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Exercise 2: Basic Queries ‚Äî SELECT, WHERE, GROUP BY üìä\n",
    "\n",
    "These are the bread-and-butter of HiveQL. If you know SQL, you already know this!\n",
    "\n",
    "### Query Pattern\n",
    "```sql\n",
    "SELECT column1, AGG(column2)\n",
    "FROM table_name\n",
    "WHERE condition\n",
    "GROUP BY column1\n",
    "ORDER BY AGG(column2) DESC\n",
    "LIMIT N;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Count crimes by type (same as Milestone 1, Task 2!)\n",
    "# In MapReduce this required a mapper + reducer + cluster job.\n",
    "# In HiveQL, it's ONE line:\n",
    "\n",
    "print(\"üìä Crime Type Distribution\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "hive_query('''\n",
    "    SELECT primary_type, COUNT(*) AS cnt\n",
    "    FROM chicago_crimes\n",
    "    GROUP BY primary_type\n",
    "    ORDER BY cnt DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Filter ‚Äî only crimes with arrests\n",
    "print(\"üöî Crimes with Arrests by Type\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "hive_query('''\n",
    "    SELECT primary_type, COUNT(*) AS arrest_count\n",
    "    FROM chicago_crimes\n",
    "    WHERE arrest = 1\n",
    "    GROUP BY primary_type\n",
    "    ORDER BY arrest_count DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Top 5 crime locations\n",
    "print(\"üìç Top 5 Crime Locations\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "hive_query('''\n",
    "    SELECT location_desc, COUNT(*) AS cnt\n",
    "    FROM chicago_crimes\n",
    "    GROUP BY location_desc\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 5\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "### üéØ Your Turn: Basic Queries\n",
    "\n",
    "**Task 1**: Write a query to count crimes per year. Extract the year from the `date` column using `SUBSTR(date, 7, 4)`.\n",
    "\n",
    "**Task 2**: Write a query to find how many crimes occurred on the STREET in district 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 1: Count crimes per year\n",
    "# Hint: SELECT SUBSTR(date, 7, 4) AS year, COUNT(*) AS cnt\n",
    "#       FROM chicago_crimes GROUP BY ... ORDER BY ...\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 2: Count STREET crimes in district 3\n",
    "# Hint: Use WHERE with two conditions (AND)\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Exercise 3: Aggregations + HAVING üìà\n",
    "\n",
    "### WHERE vs HAVING\n",
    "\n",
    "| Clause | Filters... | Timing |\n",
    "|--------|-----------|--------|\n",
    "| `WHERE` | Individual rows | **Before** grouping |\n",
    "| `HAVING` | Groups | **After** grouping |\n",
    "\n",
    "**Rule of thumb**: Use `WHERE` when filtering raw data, use `HAVING` when filtering aggregated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find districts with MORE than 100 crimes\n",
    "print(\"üè¢ High-Crime Districts (> 100 crimes)\")\n",
    "print(\"‚îÄ\" * 40)\n",
    "hive_query('''\n",
    "    SELECT district, COUNT(*) AS total_crimes\n",
    "    FROM chicago_crimes\n",
    "    GROUP BY district\n",
    "    HAVING COUNT(*) > 100\n",
    "    ORDER BY total_crimes DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrest rate by crime type ‚Äî combining multiple aggregations\n",
    "print(\"üìà Arrest Rate by Crime Type\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "hive_query('''\n",
    "    SELECT \n",
    "        primary_type,\n",
    "        COUNT(*) AS total,\n",
    "        SUM(CASE WHEN arrest = 1 THEN 1 ELSE 0 END) AS arrests,\n",
    "        ROUND(\n",
    "            SUM(CASE WHEN arrest = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*),\n",
    "            1\n",
    "        ) AS arrest_rate_pct\n",
    "    FROM chicago_crimes\n",
    "    GROUP BY primary_type\n",
    "    ORDER BY arrest_rate_pct DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5b6c7",
   "metadata": {},
   "source": [
    "### üéØ Your Turn: Aggregations\n",
    "\n",
    "**Task 1**: Find crime types that have an arrest rate **greater than 50%**. Use `HAVING`.\n",
    "\n",
    "**Task 2**: For each year, calculate the total number of crimes AND the number of arrests. Order by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 1: Crime types with arrest rate > 50%\n",
    "# Hint: Use the arrest rate formula from above inside a HAVING clause\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 2: Per-year crime count and arrest count\n",
    "# Hint: SELECT SUBSTR(date,7,4) AS year, COUNT(*), SUM(CASE WHEN arrest=1 ...) ...\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e9f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Exercise 4: JOINs ‚Äî Combining Tables üîó\n",
    "\n",
    "### JOIN Types\n",
    "\n",
    "| Type | Returns |\n",
    "|------|--------|\n",
    "| `INNER JOIN` | Only rows that match in **both** tables |\n",
    "| `LEFT JOIN` | All rows from left + matching from right |\n",
    "| `RIGHT JOIN` | All rows from right + matching from left |\n",
    "| `FULL OUTER JOIN` | All rows from both tables |\n",
    "\n",
    "We'll join `nyc_taxi` with `nyc_weather` on the date to analyze how weather affects taxi trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN: Taxi trips + Weather on the same day\n",
    "print(\"üîó Taxi Trips with Weather Data (sample)\")\n",
    "print(\"‚îÄ\" * 60)\n",
    "hive_query('''\n",
    "    SELECT \n",
    "        t.trip_id,\n",
    "        t.pickup_date,\n",
    "        t.fare,\n",
    "        t.distance,\n",
    "        w.condition,\n",
    "        w.temp_high\n",
    "    FROM nyc_taxi t\n",
    "    INNER JOIN nyc_weather w ON t.pickup_date = w.date\n",
    "    LIMIT 10\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytical JOIN: Average fare and distance by weather condition\n",
    "print(\"üå§Ô∏è Average Taxi Metrics by Weather\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "hive_query('''\n",
    "    SELECT \n",
    "        w.condition,\n",
    "        COUNT(*) AS num_trips,\n",
    "        ROUND(AVG(t.fare), 2) AS avg_fare,\n",
    "        ROUND(AVG(t.distance), 2) AS avg_distance,\n",
    "        ROUND(AVG(t.tip), 2) AS avg_tip\n",
    "    FROM nyc_taxi t\n",
    "    INNER JOIN nyc_weather w ON t.pickup_date = w.date\n",
    "    GROUP BY w.condition\n",
    "    ORDER BY num_trips DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1b2c3",
   "metadata": {},
   "source": [
    "### üéØ Your Turn: JOINs\n",
    "\n",
    "**Task 1**: Find the average taxi fare on days when the temperature was above 70¬∞F vs. below 40¬∞F.\n",
    "\n",
    "**Task 2**: Find the total number of taxi trips and total revenue for each payment type, but only on rainy days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 1: Average fare by temperature bracket\n",
    "# Hint: JOIN taxi with weather, use CASE WHEN w.temp_high > 70 THEN 'Hot'\n",
    "#       WHEN w.temp_high < 40 THEN 'Cold' ELSE 'Moderate' END AS temp_bracket\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 2: Payment type revenue on rainy days only\n",
    "# Hint: JOIN + WHERE w.condition = 'Rain' + GROUP BY payment_type\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Exercise 5: Window Functions ü™ü\n",
    "\n",
    "Window functions perform calculations **across a set of rows** related to the current row ‚Äî without collapsing the rows like GROUP BY does.\n",
    "\n",
    "### Syntax\n",
    "```sql\n",
    "FUNCTION() OVER (\n",
    "    PARTITION BY column   -- groups to compute within\n",
    "    ORDER BY column       -- ordering within each group\n",
    ")\n",
    "```\n",
    "\n",
    "### Common Window Functions\n",
    "\n",
    "| Function | Purpose |\n",
    "|----------|--------|\n",
    "| `ROW_NUMBER()` | Assign a unique sequential number |\n",
    "| `RANK()` | Rank with gaps (ties get same rank) |\n",
    "| `DENSE_RANK()` | Rank without gaps |\n",
    "| `SUM() OVER()` | Running/cumulative total |\n",
    "| `AVG() OVER()` | Running/moving average |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANK: Rank crime types by frequency within each district\n",
    "print(\"üèÜ Top Crime Types per District\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "hive_query('''\n",
    "    SELECT * FROM (\n",
    "        SELECT \n",
    "            district,\n",
    "            primary_type,\n",
    "            COUNT(*) AS crime_count,\n",
    "            RANK() OVER (\n",
    "                PARTITION BY district \n",
    "                ORDER BY COUNT(*) DESC\n",
    "            ) AS rnk\n",
    "        FROM chicago_crimes\n",
    "        GROUP BY district, primary_type\n",
    "    )\n",
    "    WHERE rnk <= 3\n",
    "    ORDER BY district, rnk\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running total: Cumulative fare by trip order\n",
    "print(\"üí∞ Running Total of Taxi Fares (first 15 trips)\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "hive_query('''\n",
    "    SELECT \n",
    "        trip_id,\n",
    "        fare,\n",
    "        ROUND(SUM(fare) OVER (ORDER BY trip_id), 2) AS cumulative_fare\n",
    "    FROM nyc_taxi\n",
    "    ORDER BY trip_id\n",
    "    LIMIT 15\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8ca",
   "metadata": {},
   "source": [
    "### üéØ Your Turn: Window Functions\n",
    "\n",
    "**Task 1**: Use `ROW_NUMBER()` to assign a unique row number to each crime within each district, ordered by `id`. Show the first 2 rows per district.\n",
    "\n",
    "**Task 2**: Calculate a running average of taxi fares using `AVG(fare) OVER (ORDER BY trip_id ROWS BETWEEN 4 PRECEDING AND CURRENT ROW)`. Show the first 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 1: ROW_NUMBER per district, show first 2 per district\n",
    "# Hint: Use a subquery with ROW_NUMBER() OVER (PARTITION BY district ORDER BY id)\n",
    "#       then filter WHERE row_num <= 2\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Task 2: Moving average of taxi fares (5-trip window)\n",
    "# Hint: ROUND(AVG(fare) OVER (ORDER BY trip_id ROWS BETWEEN 4 PRECEDING AND CURRENT ROW), 2)\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Exercise 6: EXPLAIN ‚Äî Understanding Query Execution üîç\n",
    "\n",
    "In Hive, `EXPLAIN` shows you **how** the query will be executed (which MapReduce/Tez stages are created). In our emulator, SQLite's `EXPLAIN QUERY PLAN` gives similar insight.\n",
    "\n",
    "### Why care about EXPLAIN?\n",
    "- Understand if your query does a **full table scan** vs. using an **index**\n",
    "- See if joins are efficient\n",
    "- Diagnose slow queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN a simple query\n",
    "print(\"üîç Execution Plan: COUNT crimes by type\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "hive_query('''\n",
    "    EXPLAIN QUERY PLAN\n",
    "    SELECT primary_type, COUNT(*)\n",
    "    FROM chicago_crimes\n",
    "    GROUP BY primary_type\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index (simulates what Hive partitioning does)\n",
    "hive_query('CREATE INDEX idx_district ON chicago_crimes(district)')\n",
    "\n",
    "# EXPLAIN with index\n",
    "print(\"\\nüîç Execution Plan: Query with INDEX (like partition pruning)\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "hive_query('''\n",
    "    EXPLAIN QUERY PLAN\n",
    "    SELECT primary_type, COUNT(*)\n",
    "    FROM chicago_crimes\n",
    "    WHERE district = 3\n",
    "    GROUP BY primary_type\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN a JOIN query\n",
    "print(\"üîç Execution Plan: JOIN query\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "hive_query('''\n",
    "    EXPLAIN QUERY PLAN\n",
    "    SELECT w.condition, AVG(t.fare)\n",
    "    FROM nyc_taxi t\n",
    "    JOIN nyc_weather w ON t.pickup_date = w.date\n",
    "    GROUP BY w.condition\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. üèÜ Challenge: Full Analytics Pipeline\n",
    "\n",
    "Put it all together! Write a **single query** that answers:\n",
    "\n",
    "> **\"For each district, what is the #1 most common crime type, how many times did it occur, and what is its arrest rate?\"**\n",
    "\n",
    "This requires combining: GROUP BY, window functions (RANK), CASE WHEN, and a subquery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Challenge ‚Äî Top crime type per district with arrest rate\n",
    "# Expected output columns: district, primary_type, crime_count, arrest_rate_pct\n",
    "#\n",
    "# Approach:\n",
    "# 1. Inner query: GROUP BY district, primary_type to get counts + arrest rates\n",
    "# 2. Add RANK() OVER (PARTITION BY district ORDER BY count DESC) \n",
    "# 3. Outer query: filter WHERE rnk = 1\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. HiveQL Cheat Sheet üìã\n",
    "\n",
    "### DDL (Data Definition)\n",
    "\n",
    "| Command | Example |\n",
    "|---------|--------|\n",
    "| Create table | `CREATE TABLE t (col1 INT, col2 STRING)` |\n",
    "| Create external | `CREATE EXTERNAL TABLE t (...) LOCATION '/path'` |\n",
    "| CTAS | `CREATE TABLE t AS SELECT ...` |\n",
    "| Drop table | `DROP TABLE t` |\n",
    "| Describe | `DESCRIBE t` |\n",
    "\n",
    "### DML (Queries)\n",
    "\n",
    "| Pattern | Example |\n",
    "|---------|--------|\n",
    "| Basic select | `SELECT col FROM t WHERE cond` |\n",
    "| Aggregation | `SELECT col, COUNT(*) FROM t GROUP BY col` |\n",
    "| HAVING | `... GROUP BY col HAVING COUNT(*) > 10` |\n",
    "| JOIN | `SELECT ... FROM t1 JOIN t2 ON t1.key = t2.key` |\n",
    "| Window | `RANK() OVER (PARTITION BY col ORDER BY col2)` |\n",
    "| Subquery | `SELECT * FROM (SELECT ...) WHERE rnk = 1` |\n",
    "\n",
    "### Common Functions\n",
    "\n",
    "| Category | Functions |\n",
    "|----------|----------|\n",
    "| Aggregate | `COUNT`, `SUM`, `AVG`, `MIN`, `MAX` |\n",
    "| String | `UPPER`, `LOWER`, `SUBSTR`, `CONCAT`, `LENGTH` |\n",
    "| Conditional | `CASE WHEN ... THEN ... ELSE ... END` |\n",
    "| Rounding | `ROUND(value, decimals)` |\n",
    "| Window | `ROW_NUMBER`, `RANK`, `DENSE_RANK`, `LAG`, `LEAD` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a0",
   "metadata": {},
   "source": [
    "## 11. üè† Preparation for Notebook 4B\n",
    "\n",
    "In the next notebook, you'll run **real HiveQL queries on the Hadoop cluster**.\n",
    "\n",
    "**Before class:**\n",
    "1. Make sure you can SSH into the cluster\n",
    "2. Review the `CREATE EXTERNAL TABLE` syntax ‚Äî you'll create a table over `/data/chicago_crimes.csv`\n",
    "3. Think about this: the same crime queries you wrote here will now run as distributed Tez/MapReduce jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c8f7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfaisal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
